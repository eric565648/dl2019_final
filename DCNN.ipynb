{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.05\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 100\n",
    "DATA_FOLDER = 'set03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Loss_d = []\n",
    "Train_Loss_phi = []\n",
    "Train_Loss = []\n",
    "Test_Loss_d = []\n",
    "Test_Loss_phi = []\n",
    "Test_Loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        \n",
    "        img = pd.read_csv(DATA_FOLDER + '_train_img.csv')\n",
    "        label = pd.read_csv(DATA_FOLDER + '_train_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "    else:\n",
    "        img = pd.read_csv(DATA_FOLDER + '_test_img.csv')\n",
    "        label = pd.read_csv(DATA_FOLDER + '_test_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "\n",
    "\n",
    "class Loader(Data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (string): Root path of the dataset.\n",
    "            mode : Indicate procedure status(training or testing)\n",
    "\n",
    "            self.img_name (string list): String list that store all image names.\n",
    "            self.label (int or float list): Numerical list that store all ground truth label values.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.img_name, self.label = getData(mode)\n",
    "        self.mode = mode\n",
    "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        #------------return the size of dataset\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #-------------Get the image path from 'self.img_name' and load it.\n",
    "                  \n",
    "        path = self.root + str(self.img_name[index]) + '.png'\n",
    "        img_as_img = Image.open(path)\n",
    "        #img = img.resize(,Image.ANTIALIAS)\n",
    "        #box=(0,240,640,480)\n",
    "        #img=img.crop(box)\n",
    "        \n",
    "        #-------------Get the ground truth label from self.label\"\"\"\n",
    "        label = torch.from_numpy(self.label)[index]\n",
    "        \n",
    "        #-------------Transform the .jpeg rgb images\n",
    "        if self.mode == 'train':\n",
    "            transform1 = transforms.Compose([\n",
    "#                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "#                 transforms.RandomVerticalFlip(p=0.5),\n",
    "#                 transforms.RandomRotation(degrees=(-45,45), resample=False, expand=False, center=None),\n",
    "#                 transforms.ColorJitter(contrast=(0,1)),\n",
    "                transforms.Resize(( 280, 210)),\n",
    "                transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)),#range [0, 255] ->[-1.0,1.0]\n",
    "                \n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            transform1 = transforms.Compose([\n",
    "                transforms.Resize(( 280, 210)),\n",
    "                transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5)),\n",
    "             \n",
    "                ]\n",
    "            )\n",
    "        img_tran = transform1(img_as_img)\n",
    "                \n",
    "        #-------------Return processed image and label\n",
    "        return img_tran, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 2652 images...\n",
      "> Found 294 images...\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f37712c8b00>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f37712c8048>\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_data=Loader('./'+ DATA_FOLDER +'/','train')\n",
    "test_data=Loader('./'+ DATA_FOLDER +'/','test')\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)\n",
    "print (train_loader)\n",
    "print (test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "    \n",
    "        #####---1\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1.0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        #####\n",
    "        \n",
    "        #####---2\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=(2, 2) ,bias=True, groups=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1.0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        #####\n",
    "        \n",
    "        #####---3\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=(3, 3), padding=(1, 1), bias=True, groups=2)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=(1, 1), bias=True, groups=2)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=3 , stride=2, padding=0)\n",
    "        #####\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_features=8960, out_features=4096, bias=True)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=256, bias=False)\n",
    "        self.fc9 = nn.Linear(in_features=256, out_features=2, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        ###-----1------\n",
    "        out = self.conv1(x)\n",
    "        #out = self.batchnorm1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool1(out)        \n",
    "        out = self.norm1(out)\n",
    "        #out = F.dropout(out, p=0.5)\n",
    "        \n",
    "        ###-----2------\n",
    "        out = self.conv2(out)\n",
    "        #out = self.batchnorm2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.norm2(out)\n",
    "        #out = F.dropout(out, p=0.5)\n",
    "        \n",
    "        ###-----3------\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        ###-----4------\n",
    "        out = self.conv4(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool5(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1) #flatten\n",
    "        out = self.fc6(out)\n",
    "        out = F.leaky_relu(out,0.05)\n",
    "        out = F.dropout(out, p=0.5)\n",
    "        \n",
    "        out = self.fc7(out)\n",
    "        out = F.leaky_relu(out,0.05)\n",
    "        out = F.dropout(out, p=0.5)\n",
    "      \n",
    "        out = self.fc8(out)\n",
    "        out = F.leaky_relu(out,0.05)\n",
    "        out = F.dropout(out, p=0.5)\n",
    "        \n",
    "        out = self.fc9(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        #out = torch.tanh(out)\n",
    "        #out = F.softsign(out)\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DeepConv(epoch):\n",
    "    model_DeepConvNet.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(device=device, dtype=torch.float), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_DeepConvNet(data)\n",
    "        target = target.float()\n",
    "        loss_d = Loss(output[0], target[0])\n",
    "        loss_phi = Loss(output[1], target[1])\n",
    "        loss = loss_d + loss_phi\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"output\" ,output.cpu().detach().numpy().squeeze()[0:3])\n",
    "#         print(\"ground truth\" ,target.cpu().detach().numpy().squeeze()[0:3])\n",
    "    Train_Loss.append(round((loss.data).cpu().numpy().tolist(),6))\n",
    "    Train_Loss_d.append(round((loss_d.data).cpu().numpy().tolist(),6))\n",
    "    Train_Loss_phi.append(round((loss_phi.data).cpu().numpy().tolist(),6))\n",
    "   \n",
    "    print('Train Epoch: {} \\t Loss_d: {} Loss_phi:{}'.format(\n",
    "            epoch, loss_d.data , loss_phi.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DeepConv(epoch):\n",
    "    model_DeepConvNet.eval()\n",
    "    test_loss_d = 0.0\n",
    "    test_loss_phi = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to(device=device, dtype=torch.float), target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model_DeepConvNet(data)\n",
    "        target = target.float()\n",
    "        test_loss_d = Loss(output[0], target[0])\n",
    "        test_loss_phi = Loss(output[1], target[1])\n",
    "    \n",
    "    if(epoch==1):\n",
    "        print(\" ground truth\\n\" ,target.cpu().detach().numpy().squeeze()[0:8])\n",
    "    print(output.cpu().detach().numpy().squeeze()[0:8])\n",
    "    \n",
    "    Test_Loss_d.append(round((test_loss_d.data).cpu().numpy().tolist(),6))\n",
    "    Test_Loss_phi.append(round((test_loss_phi.data).cpu().numpy().tolist(),6))\n",
    "        \n",
    "    print('========Test set: Average loss d:{}\\t loss phi:{}========\\n'\n",
    "          .format(test_loss_d,test_loss_phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepConvNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), bias=False)\n",
      "  (batchnorm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc6): Linear(in_features=8960, out_features=4096, bias=True)\n",
      "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc8): Linear(in_features=4096, out_features=256, bias=False)\n",
      "  (fc9): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_DeepConvNet = DeepConvNet().cuda(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    model_DeepConvNet.to(device) \n",
    "#------------define optimizer/loss function\n",
    "Loss = nn.MSELoss(reduction='mean')    \n",
    "optimizer = torch.optim.SGD(model_DeepConvNet.parameters(), lr=LR, momentum=0.9, \n",
    "                            dampening=0, weight_decay=0.0005, nesterov=False)\n",
    "print(model_DeepConvNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \t Loss_d: 0.025751203298568726 Loss_phi:0.024926993995904922\n",
      " ground truth\n",
      " [[-0.08273652 -0.94172   ]\n",
      " [-0.11888251  0.37627342]\n",
      " [ 0.05218287  0.7489732 ]\n",
      " [-0.09701227  0.3416342 ]\n",
      " [-0.02468774  0.07899258]\n",
      " [ 0.00708377 -0.32711706]\n",
      " [-0.02614982  0.09217016]\n",
      " [-0.03992722  0.04558269]]\n",
      "[[ 0.08923959 -0.1495622 ]\n",
      " [ 0.0868092  -0.13917881]\n",
      " [ 0.08068758 -0.14746723]\n",
      " [ 0.08472417 -0.14108004]\n",
      " [ 0.08816658 -0.14835301]\n",
      " [ 0.09156924 -0.14135914]\n",
      " [ 0.09023021 -0.13693337]\n",
      " [ 0.0897599  -0.15014556]]\n",
      "========Test set: Average loss d:0.32854488492012024\t loss phi:0.15400005877017975========\n",
      "\n",
      "Train Epoch: 2 \t Loss_d: 0.024938959628343582 Loss_phi:0.022831931710243225\n",
      "[[ 0.08579266 -0.14122088]\n",
      " [ 0.0909816  -0.13661613]\n",
      " [ 0.08419894 -0.15037055]\n",
      " [ 0.07615604 -0.13969015]\n",
      " [ 0.09048502 -0.14063579]\n",
      " [ 0.09220293 -0.13511306]\n",
      " [ 0.07946342 -0.13450846]\n",
      " [ 0.08544393 -0.1425368 ]]\n",
      "========Test set: Average loss d:0.3346004784107208\t loss phi:0.15354932844638824========\n",
      "\n",
      "Train Epoch: 3 \t Loss_d: 0.022936508059501648 Loss_phi:0.021945945918560028\n",
      "[[ 0.07890812 -0.15050626]\n",
      " [ 0.08113792 -0.14875297]\n",
      " [ 0.08290442 -0.13210763]\n",
      " [ 0.08063233 -0.13676187]\n",
      " [ 0.08317134 -0.1456541 ]\n",
      " [ 0.08468096 -0.13470195]\n",
      " [ 0.08589142 -0.13576026]\n",
      " [ 0.08530807 -0.13525121]]\n",
      "========Test set: Average loss d:0.32607409358024597\t loss phi:0.15783044695854187========\n",
      "\n",
      "Train Epoch: 4 \t Loss_d: 0.02461177483201027 Loss_phi:0.025934208184480667\n",
      "[[ 0.07872778 -0.14888386]\n",
      " [ 0.08264293 -0.15591256]\n",
      " [ 0.08022271 -0.15021014]\n",
      " [ 0.08093388 -0.15504627]\n",
      " [ 0.0809627  -0.15298131]\n",
      " [ 0.08027713 -0.14790432]\n",
      " [ 0.08149122 -0.1521117 ]\n",
      " [ 0.08218433 -0.15491463]]\n",
      "========Test set: Average loss d:0.32732993364334106\t loss phi:0.16191720962524414========\n",
      "\n",
      "Train Epoch: 5 \t Loss_d: 0.024931324645876884 Loss_phi:0.024641158059239388\n",
      "[[ 0.07826046 -0.15107685]\n",
      " [ 0.07922833 -0.1503591 ]\n",
      " [ 0.07953235 -0.14960368]\n",
      " [ 0.07799537 -0.1503579 ]\n",
      " [ 0.07944698 -0.14956068]\n",
      " [ 0.0769083  -0.15067463]\n",
      " [ 0.07860313 -0.149916  ]\n",
      " [ 0.07778513 -0.15048377]]\n",
      "========Test set: Average loss d:0.32551831007003784\t loss phi:0.15829487144947052========\n",
      "\n",
      "Train Epoch: 6 \t Loss_d: 0.023937225341796875 Loss_phi:0.025643792003393173\n",
      "[[ 0.07870424 -0.15576778]\n",
      " [ 0.08100407 -0.1434775 ]\n",
      " [ 0.08186012 -0.14418277]\n",
      " [ 0.07889404 -0.15442502]\n",
      " [ 0.07938778 -0.15592326]\n",
      " [ 0.07928472 -0.15501395]\n",
      " [ 0.07908933 -0.15526697]\n",
      " [ 0.07902553 -0.1554357 ]]\n",
      "========Test set: Average loss d:0.32189202308654785\t loss phi:0.15504786372184753========\n",
      "\n",
      "Train Epoch: 7 \t Loss_d: 0.028627309948205948 Loss_phi:0.020759671926498413\n",
      "[[ 0.07808825 -0.12136875]\n",
      " [ 0.08230009 -0.14811724]\n",
      " [ 0.07887252 -0.11840732]\n",
      " [ 0.07665839 -0.12405933]\n",
      " [ 0.07860623 -0.11470215]\n",
      " [ 0.083046   -0.14717259]\n",
      " [ 0.08737955 -0.14697498]\n",
      " [ 0.07634168 -0.12203111]]\n",
      "========Test set: Average loss d:0.34942036867141724\t loss phi:0.15773002803325653========\n",
      "\n",
      "Train Epoch: 8 \t Loss_d: 0.024543244391679764 Loss_phi:0.023980073630809784\n",
      "[[ 0.0787186  -0.1457671 ]\n",
      " [ 0.0793105  -0.14337683]\n",
      " [ 0.07588999 -0.14707682]\n",
      " [ 0.07772575 -0.14368899]\n",
      " [ 0.07544312 -0.14616686]\n",
      " [ 0.07899418 -0.14674532]\n",
      " [ 0.07647062 -0.14587821]\n",
      " [ 0.07732807 -0.14722845]]\n",
      "========Test set: Average loss d:0.329804390668869\t loss phi:0.15465840697288513========\n",
      "\n",
      "Train Epoch: 9 \t Loss_d: 0.02439378947019577 Loss_phi:0.024010296911001205\n",
      "[[ 0.08066845 -0.14966682]\n",
      " [ 0.08353254 -0.14565761]\n",
      " [ 0.08101744 -0.14707196]\n",
      " [ 0.07991777 -0.15141386]\n",
      " [ 0.07863916 -0.15133926]\n",
      " [ 0.08014148 -0.1501802 ]\n",
      " [ 0.08088568 -0.14938262]\n",
      " [ 0.08174405 -0.14696065]]\n",
      "========Test set: Average loss d:0.32702475786209106\t loss phi:0.15669193863868713========\n",
      "\n",
      "Train Epoch: 10 \t Loss_d: 0.02491573616862297 Loss_phi:0.024966483935713768\n",
      "[[ 0.07743789 -0.15202874]\n",
      " [ 0.07851822 -0.15125929]\n",
      " [ 0.08063921 -0.14876512]\n",
      " [ 0.07747943 -0.15142556]\n",
      " [ 0.07830779 -0.15174112]\n",
      " [ 0.07894309 -0.14984868]\n",
      " [ 0.08023473 -0.14800775]\n",
      " [ 0.07901403 -0.14929478]]\n",
      "========Test set: Average loss d:0.3246340751647949\t loss phi:0.1586288958787918========\n",
      "\n",
      "Train Epoch: 11 \t Loss_d: 0.02551679126918316 Loss_phi:0.02537349984049797\n",
      "[[ 0.07981618 -0.14894263]\n",
      " [ 0.07902589 -0.15005675]\n",
      " [ 0.07824014 -0.15196615]\n",
      " [ 0.07762542 -0.15275738]\n",
      " [ 0.07989418 -0.14923586]\n",
      " [ 0.08000297 -0.14878495]\n",
      " [ 0.07785509 -0.151951  ]\n",
      " [ 0.07749231 -0.15262003]]\n",
      "========Test set: Average loss d:0.3274596631526947\t loss phi:0.1580955982208252========\n",
      "\n",
      "Train Epoch: 12 \t Loss_d: 0.02466394379734993 Loss_phi:0.02462560310959816\n",
      "[[ 0.07938683 -0.14865795]\n",
      " [ 0.07939458 -0.14920825]\n",
      " [ 0.07907942 -0.14853539]\n",
      " [ 0.07938945 -0.14797734]\n",
      " [ 0.07934371 -0.14889503]\n",
      " [ 0.07917786 -0.14913465]\n",
      " [ 0.08010083 -0.1493433 ]\n",
      " [ 0.07923795 -0.14782579]]\n",
      "========Test set: Average loss d:0.32761573791503906\t loss phi:0.15772239863872528========\n",
      "\n",
      "Train Epoch: 13 \t Loss_d: 0.02493828721344471 Loss_phi:0.024628248065710068\n",
      "[[ 0.07924852 -0.14996739]\n",
      " [ 0.0788946  -0.14965096]\n",
      " [ 0.07944017 -0.14991698]\n",
      " [ 0.07870539 -0.1501798 ]\n",
      " [ 0.07877872 -0.1501441 ]\n",
      " [ 0.07876816 -0.1500822 ]\n",
      " [ 0.08000573 -0.15024343]\n",
      " [ 0.07871754 -0.14992532]]\n",
      "========Test set: Average loss d:0.32655569911003113\t loss phi:0.15785612165927887========\n",
      "\n",
      "Train Epoch: 14 \t Loss_d: 0.02504657953977585 Loss_phi:0.024719584733247757\n",
      "[[ 0.0785409  -0.15029106]\n",
      " [ 0.07840046 -0.15035476]\n",
      " [ 0.07984762 -0.14989127]\n",
      " [ 0.07916791 -0.14981037]\n",
      " [ 0.07903569 -0.15037163]\n",
      " [ 0.0787729  -0.15081668]\n",
      " [ 0.07905333 -0.15046555]\n",
      " [ 0.07888976 -0.15001644]]\n",
      "========Test set: Average loss d:0.32618507742881775\t loss phi:0.15812891721725464========\n",
      "\n",
      "Train Epoch: 15 \t Loss_d: 0.025293856859207153 Loss_phi:0.024570316076278687\n",
      "[[ 0.07837013 -0.15130778]\n",
      " [ 0.07831918 -0.15217079]\n",
      " [ 0.07881205 -0.14965808]\n",
      " [ 0.07819369 -0.15155232]\n",
      " [ 0.07683069 -0.1524111 ]\n",
      " [ 0.07826692 -0.1496142 ]\n",
      " [ 0.07825091 -0.15245605]\n",
      " [ 0.07894167 -0.14941391]]\n",
      "========Test set: Average loss d:0.3253534436225891\t loss phi:0.1590709090232849========\n",
      "\n",
      "Train Epoch: 16 \t Loss_d: 0.025356143712997437 Loss_phi:0.025260325521230698\n",
      "[[ 0.07876237 -0.15167885]\n",
      " [ 0.07868711 -0.15080824]\n",
      " [ 0.07860281 -0.15044123]\n",
      " [ 0.07946096 -0.1506055 ]\n",
      " [ 0.0783748  -0.1522541 ]\n",
      " [ 0.07863821 -0.15172079]\n",
      " [ 0.07991348 -0.15112899]\n",
      " [ 0.07827902 -0.15129788]]\n",
      "========Test set: Average loss d:0.32512345910072327\t loss phi:0.15842440724372864========\n",
      "\n",
      "Train Epoch: 17 \t Loss_d: 0.024966461583971977 Loss_phi:0.02468040958046913\n",
      "[[ 0.07928314 -0.14999355]\n",
      " [ 0.07949787 -0.14983219]\n",
      " [ 0.07815396 -0.15010367]\n",
      " [ 0.07857906 -0.1505142 ]\n",
      " [ 0.07889477 -0.15003306]\n",
      " [ 0.07932051 -0.15018213]\n",
      " [ 0.07936552 -0.15037575]\n",
      " [ 0.07894175 -0.14987116]]\n",
      "========Test set: Average loss d:0.32654058933258057\t loss phi:0.15807095170021057========\n",
      "\n",
      "Train Epoch: 18 \t Loss_d: 0.024935852736234665 Loss_phi:0.024823134765028954\n",
      "[[ 0.07856011 -0.1507718 ]\n",
      " [ 0.07842723 -0.15050808]\n",
      " [ 0.0792267  -0.150298  ]\n",
      " [ 0.07851359 -0.15041234]\n",
      " [ 0.0786296  -0.15041867]\n",
      " [ 0.07831265 -0.15049806]\n",
      " [ 0.07862841 -0.15027912]\n",
      " [ 0.07850885 -0.15022983]]\n",
      "========Test set: Average loss d:0.3258078396320343\t loss phi:0.15821494162082672========\n",
      "\n",
      "Train Epoch: 19 \t Loss_d: 0.025005079805850983 Loss_phi:0.024771234020590782\n",
      "[[ 0.07844006 -0.15035753]\n",
      " [ 0.0787189  -0.15031713]\n",
      " [ 0.07806905 -0.15061353]\n",
      " [ 0.07878137 -0.15053676]\n",
      " [ 0.07886121 -0.15035206]\n",
      " [ 0.07916253 -0.15028976]\n",
      " [ 0.07848971 -0.15033384]\n",
      " [ 0.07890423 -0.15036283]]\n",
      "========Test set: Average loss d:0.3261162340641022\t loss phi:0.15817198157310486========\n",
      "\n",
      "Train Epoch: 20 \t Loss_d: 0.024966377764940262 Loss_phi:0.02474852092564106\n",
      "[[ 0.0786793  -0.15046893]\n",
      " [ 0.07849205 -0.1504342 ]\n",
      " [ 0.07814418 -0.15064003]\n",
      " [ 0.07905247 -0.15069489]\n",
      " [ 0.07819649 -0.15032901]\n",
      " [ 0.07842791 -0.15057898]\n",
      " [ 0.07879686 -0.1503221 ]\n",
      " [ 0.07871766 -0.15031976]]\n",
      "========Test set: Average loss d:0.32606664299964905\t loss phi:0.1581888198852539========\n",
      "\n",
      "Train Epoch: 21 \t Loss_d: 0.024898704141378403 Loss_phi:0.024653928354382515\n",
      "[[ 0.07877835 -0.15050834]\n",
      " [ 0.07772271 -0.15093958]\n",
      " [ 0.07893766 -0.15044574]\n",
      " [ 0.07885966 -0.1503824 ]\n",
      " [ 0.07850745 -0.15099642]\n",
      " [ 0.07856356 -0.15068923]\n",
      " [ 0.07812605 -0.15085964]\n",
      " [ 0.07875954 -0.15023619]]\n",
      "========Test set: Average loss d:0.3260514736175537\t loss phi:0.15830357372760773========\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 \t Loss_d: 0.024899644777178764 Loss_phi:0.02468346245586872\n",
      "[[ 0.0786642  -0.15033308]\n",
      " [ 0.07831585 -0.15085922]\n",
      " [ 0.07884221 -0.14984497]\n",
      " [ 0.07781729 -0.15178797]\n",
      " [ 0.07866767 -0.15016241]\n",
      " [ 0.07933712 -0.1501611 ]\n",
      " [ 0.07876178 -0.15021186]\n",
      " [ 0.07777597 -0.15199858]]\n",
      "========Test set: Average loss d:0.32617175579071045\t loss phi:0.158378005027771========\n",
      "\n",
      "Train Epoch: 23 \t Loss_d: 0.025266526266932487 Loss_phi:0.02500849775969982\n",
      "[[ 0.07926783 -0.15020552]\n",
      " [ 0.07839257 -0.15261303]\n",
      " [ 0.07896414 -0.15004398]\n",
      " [ 0.07807897 -0.15251403]\n",
      " [ 0.079059   -0.1504118 ]\n",
      " [ 0.07920188 -0.15036514]\n",
      " [ 0.07888713 -0.14983742]\n",
      " [ 0.07944339 -0.15076743]]\n",
      "========Test set: Average loss d:0.32637032866477966\t loss phi:0.15931916236877441========\n",
      "\n",
      "Train Epoch: 24 \t Loss_d: 0.02489009127020836 Loss_phi:0.02474994957447052\n",
      "[[ 0.07873761 -0.150365  ]\n",
      " [ 0.07844493 -0.15025331]\n",
      " [ 0.0780946  -0.15033473]\n",
      " [ 0.07828692 -0.15017764]\n",
      " [ 0.07861119 -0.14975427]\n",
      " [ 0.07801805 -0.15025209]\n",
      " [ 0.07776211 -0.15088464]\n",
      " [ 0.0782791  -0.15031831]]\n",
      "========Test set: Average loss d:0.3261583149433136\t loss phi:0.15808425843715668========\n",
      "\n",
      "Train Epoch: 25 \t Loss_d: 0.024914667010307312 Loss_phi:0.024801550433039665\n",
      "[[ 0.07827716 -0.15025426]\n",
      " [ 0.0784293  -0.15063915]\n",
      " [ 0.07802165 -0.15068501]\n",
      " [ 0.07847977 -0.15025792]\n",
      " [ 0.0784599  -0.15022124]\n",
      " [ 0.07839859 -0.15132414]\n",
      " [ 0.07858548 -0.15035897]\n",
      " [ 0.07817591 -0.15061478]]\n",
      "========Test set: Average loss d:0.32617172598838806\t loss phi:0.15828441083431244========\n",
      "\n",
      "Train Epoch: 26 \t Loss_d: 0.02491467073559761 Loss_phi:0.024729404598474503\n",
      "[[ 0.07840777 -0.15025163]\n",
      " [ 0.07871627 -0.15011212]\n",
      " [ 0.07858311 -0.15033452]\n",
      " [ 0.07859524 -0.15027693]\n",
      " [ 0.078895   -0.15045409]\n",
      " [ 0.07855787 -0.15054707]\n",
      " [ 0.07888316 -0.15030335]\n",
      " [ 0.0784762  -0.15022844]]\n",
      "========Test set: Average loss d:0.3261948525905609\t loss phi:0.15806350111961365========\n",
      "\n",
      "Train Epoch: 27 \t Loss_d: 0.024905283004045486 Loss_phi:0.024670572951436043\n",
      "[[ 0.0781606  -0.1502558 ]\n",
      " [ 0.07787875 -0.15021524]\n",
      " [ 0.07773844 -0.15032768]\n",
      " [ 0.07803847 -0.15021887]\n",
      " [ 0.07804792 -0.1500843 ]\n",
      " [ 0.07827558 -0.15050395]\n",
      " [ 0.07848008 -0.15050586]\n",
      " [ 0.07792181 -0.15038529]]\n",
      "========Test set: Average loss d:0.3261517584323883\t loss phi:0.15795265138149261========\n",
      "\n",
      "Train Epoch: 28 \t Loss_d: 0.024926794692873955 Loss_phi:0.024729114025831223\n",
      "[[ 0.07864167 -0.15051632]\n",
      " [ 0.07814117 -0.15058146]\n",
      " [ 0.07878915 -0.15009165]\n",
      " [ 0.07840478 -0.15020624]\n",
      " [ 0.07874949 -0.15052393]\n",
      " [ 0.07882836 -0.15018176]\n",
      " [ 0.07827545 -0.15033028]\n",
      " [ 0.07850705 -0.15021075]]\n",
      "========Test set: Average loss d:0.3260231018066406\t loss phi:0.15819719433784485========\n",
      "\n",
      "Train Epoch: 29 \t Loss_d: 0.024977533146739006 Loss_phi:0.024702947586774826\n",
      "[[ 0.07825738 -0.15033244]\n",
      " [ 0.078275   -0.15029748]\n",
      " [ 0.0781662  -0.15038688]\n",
      " [ 0.07891918 -0.1504057 ]\n",
      " [ 0.07837848 -0.15015396]\n",
      " [ 0.07838505 -0.15036575]\n",
      " [ 0.07881656 -0.1504157 ]\n",
      " [ 0.07905377 -0.15087515]]\n",
      "========Test set: Average loss d:0.32610663771629333\t loss phi:0.1580740064382553========\n",
      "\n",
      "Train Epoch: 30 \t Loss_d: 0.024927951395511627 Loss_phi:0.02474154531955719\n",
      "[[ 0.07855312 -0.15016915]\n",
      " [ 0.07839122 -0.15038435]\n",
      " [ 0.0785123  -0.15066935]\n",
      " [ 0.07847092 -0.15045927]\n",
      " [ 0.07847806 -0.15052934]\n",
      " [ 0.07852945 -0.15055422]\n",
      " [ 0.0787321  -0.15040837]\n",
      " [ 0.07847085 -0.15050878]]\n",
      "========Test set: Average loss d:0.3262835443019867\t loss phi:0.15814265608787537========\n",
      "\n",
      "Train Epoch: 31 \t Loss_d: 0.02489025518298149 Loss_phi:0.024743080139160156\n",
      "[[ 0.07872093 -0.15029867]\n",
      " [ 0.07829957 -0.15036301]\n",
      " [ 0.07832917 -0.15036076]\n",
      " [ 0.07818548 -0.15062436]\n",
      " [ 0.07869972 -0.15050626]\n",
      " [ 0.07875188 -0.1504602 ]\n",
      " [ 0.07817686 -0.15062197]\n",
      " [ 0.07824332 -0.15065733]]\n",
      "========Test set: Average loss d:0.3262081444263458\t loss phi:0.15811334550380707========\n",
      "\n",
      "Train Epoch: 32 \t Loss_d: 0.02492482401430607 Loss_phi:0.024725470691919327\n",
      "[[ 0.07847079 -0.150649  ]\n",
      " [ 0.07871677 -0.15058461]\n",
      " [ 0.07853213 -0.15031035]\n",
      " [ 0.07866465 -0.1503255 ]\n",
      " [ 0.07833078 -0.150578  ]\n",
      " [ 0.07832153 -0.15050584]\n",
      " [ 0.07829381 -0.15051402]\n",
      " [ 0.07864925 -0.15036564]]\n",
      "========Test set: Average loss d:0.32589057087898254\t loss phi:0.15831243991851807========\n",
      "\n",
      "Train Epoch: 33 \t Loss_d: 0.024916118010878563 Loss_phi:0.02476549707353115\n",
      "[[ 0.07850067 -0.15035184]\n",
      " [ 0.07845693 -0.15037096]\n",
      " [ 0.07849406 -0.15051559]\n",
      " [ 0.07851804 -0.15025319]\n",
      " [ 0.0783862  -0.15042989]\n",
      " [ 0.07813933 -0.15067385]\n",
      " [ 0.07833835 -0.15070198]\n",
      " [ 0.07834444 -0.15073138]]\n",
      "========Test set: Average loss d:0.32613053917884827\t loss phi:0.15814855694770813========\n",
      "\n",
      "Train Epoch: 34 \t Loss_d: 0.024923497810959816 Loss_phi:0.02473432756960392\n",
      "[[ 0.07820849 -0.1505647 ]\n",
      " [ 0.0782406  -0.15054785]\n",
      " [ 0.07844678 -0.15065564]\n",
      " [ 0.07838387 -0.14970532]\n",
      " [ 0.07831941 -0.15017696]\n",
      " [ 0.07816656 -0.15008593]\n",
      " [ 0.07819498 -0.15003154]\n",
      " [ 0.07826464 -0.1499713 ]]\n",
      "========Test set: Average loss d:0.32591503858566284\t loss phi:0.15819907188415527========\n",
      "\n",
      "Train Epoch: 35 \t Loss_d: 0.024878138676285744 Loss_phi:0.024695105850696564\n",
      "[[ 0.07842057 -0.15006016]\n",
      " [ 0.07830718 -0.15036027]\n",
      " [ 0.07836267 -0.15033355]\n",
      " [ 0.07823943 -0.15016986]\n",
      " [ 0.07860091 -0.15033932]\n",
      " [ 0.07827343 -0.15024832]\n",
      " [ 0.07856721 -0.15000248]\n",
      " [ 0.07847797 -0.15015021]]\n",
      "========Test set: Average loss d:0.3263484537601471\t loss phi:0.15811340510845184========\n",
      "\n",
      "Train Epoch: 36 \t Loss_d: 0.02481551468372345 Loss_phi:0.024767687544226646\n",
      "[[ 0.07801335 -0.15006201]\n",
      " [ 0.07859411 -0.15038632]\n",
      " [ 0.07819138 -0.15008874]\n",
      " [ 0.07825284 -0.15070233]\n",
      " [ 0.07796197 -0.1506471 ]\n",
      " [ 0.07818735 -0.14997047]\n",
      " [ 0.07799495 -0.15013058]\n",
      " [ 0.0780638  -0.1501962 ]]\n",
      "========Test set: Average loss d:0.32628142833709717\t loss phi:0.158183753490448========\n",
      "\n",
      "Train Epoch: 37 \t Loss_d: 0.02488054521381855 Loss_phi:0.024666612967848778\n",
      "[[ 0.07835574 -0.15069166]\n",
      " [ 0.07842696 -0.15030436]\n",
      " [ 0.0783575  -0.15033042]\n",
      " [ 0.07837644 -0.15015863]\n",
      " [ 0.07825627 -0.1501317 ]\n",
      " [ 0.07836504 -0.15017697]\n",
      " [ 0.07843228 -0.15062179]\n",
      " [ 0.07840723 -0.15022004]]\n",
      "========Test set: Average loss d:0.3258383274078369\t loss phi:0.15810759365558624========\n",
      "\n",
      "Train Epoch: 38 \t Loss_d: 0.024942243471741676 Loss_phi:0.024720918387174606\n",
      "[[ 0.07828466 -0.15032588]\n",
      " [ 0.07854734 -0.15045096]\n",
      " [ 0.07825166 -0.15047157]\n",
      " [ 0.07819247 -0.15026657]\n",
      " [ 0.078417   -0.15023108]\n",
      " [ 0.07846189 -0.15019494]\n",
      " [ 0.07851114 -0.15034986]\n",
      " [ 0.07840233 -0.1504708 ]]\n",
      "========Test set: Average loss d:0.3261162340641022\t loss phi:0.15820856392383575========\n",
      "\n",
      "Train Epoch: 39 \t Loss_d: 0.02502940222620964 Loss_phi:0.02461405098438263\n",
      "[[ 0.07824349 -0.14993733]\n",
      " [ 0.07863244 -0.15085067]\n",
      " [ 0.07859317 -0.15083045]\n",
      " [ 0.0786406  -0.15077971]\n",
      " [ 0.07860888 -0.15121575]\n",
      " [ 0.0786055  -0.15066609]\n",
      " [ 0.07824785 -0.1499566 ]\n",
      " [ 0.07823909 -0.1497174 ]]\n",
      "========Test set: Average loss d:0.3264171779155731\t loss phi:0.15843600034713745========\n",
      "\n",
      "Train Epoch: 40 \t Loss_d: 0.0247325599193573 Loss_phi:0.024694964289665222\n",
      "[[ 0.07836177 -0.15014489]\n",
      " [ 0.07834111 -0.15038905]\n",
      " [ 0.07813238 -0.14965256]\n",
      " [ 0.07830806 -0.14967509]\n",
      " [ 0.07828566 -0.14958249]\n",
      " [ 0.07838168 -0.15031338]\n",
      " [ 0.07831946 -0.14978436]\n",
      " [ 0.07811899 -0.14961883]]\n",
      "========Test set: Average loss d:0.3262719213962555\t loss phi:0.15813525021076202========\n",
      "\n",
      "Train Epoch: 41 \t Loss_d: 0.024907361716032028 Loss_phi:0.02471126988530159\n",
      "[[ 0.07819503 -0.15036698]\n",
      " [ 0.07817656 -0.150482  ]\n",
      " [ 0.07828949 -0.1501858 ]\n",
      " [ 0.07822556 -0.15035598]\n",
      " [ 0.07838077 -0.15034784]\n",
      " [ 0.07826823 -0.15033779]\n",
      " [ 0.0783622  -0.15022597]\n",
      " [ 0.07822188 -0.1502653 ]]\n",
      "========Test set: Average loss d:0.32606932520866394\t loss phi:0.1581517904996872========\n",
      "\n",
      "Train Epoch: 42 \t Loss_d: 0.024904197081923485 Loss_phi:0.02471826784312725\n",
      "[[ 0.07826937 -0.15044223]\n",
      " [ 0.07813946 -0.15055981]\n",
      " [ 0.07838786 -0.15030219]\n",
      " [ 0.07845719 -0.15033269]\n",
      " [ 0.07841754 -0.15024512]\n",
      " [ 0.07836658 -0.15047894]\n",
      " [ 0.07880951 -0.15026966]\n",
      " [ 0.07841381 -0.15062894]]\n",
      "========Test set: Average loss d:0.3260217010974884\t loss phi:0.1581854522228241========\n",
      "\n",
      "Train Epoch: 43 \t Loss_d: 0.024930041283369064 Loss_phi:0.024692969396710396\n",
      "[[ 0.07847657 -0.15044063]\n",
      " [ 0.07836602 -0.1506435 ]\n",
      " [ 0.07845701 -0.1502281 ]\n",
      " [ 0.07847917 -0.15024963]\n",
      " [ 0.07834756 -0.15026858]\n",
      " [ 0.07846476 -0.1501237 ]\n",
      " [ 0.07840383 -0.15062363]\n",
      " [ 0.07835848 -0.1507098 ]]\n",
      "========Test set: Average loss d:0.3260563611984253\t loss phi:0.15827421844005585========\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a08317a7f701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#---------------Train-----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_DeepConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_DeepConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-7674e24e93af>\u001b[0m in \u001b[0;36mtrain_DeepConv\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_DeepConvNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-70c9e551904c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 ]\n\u001b[1;32m     65\u001b[0m             )\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mimg_tran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m#-------------Return processed image and label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#---------------Train-----------------\n",
    "for epoch in range(1,EPOCH+1):\n",
    "    train_DeepConv(epoch)\n",
    "    test_DeepConv(epoch)\n",
    "    if (epoch%10==0):\n",
    "        PATH ='./model/'+str(epoch)+'-linear.pkl'\n",
    "        torch.save(model_DeepConvNet.state_dict(), PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle a variable to a file\n",
    "file = open('Train_loss_d.pickle', 'wb')\n",
    "pickle.dump(Train_Loss_d, file)\n",
    "file.close()\n",
    "# pickle a variable to a file\n",
    "file = open('Train_loss_phi.pickle', 'wb')\n",
    "pickle.dump(Train_Loss_phi, file)\n",
    "file.close()\n",
    "# pickle a variable to a file\n",
    "file = open('Train_loss.pickle', 'wb')\n",
    "pickle.dump(Train_Loss, file)\n",
    "file.close()\n",
    "# pickle a variable to a file\n",
    "file = open('Test_loss_d.pickle', 'wb')\n",
    "pickle.dump(Test_Loss_d, file)\n",
    "file.close()\n",
    "# pickle a variable to a file\n",
    "file = open('Test_loss_phi.pickle', 'wb')\n",
    "pickle.dump(Test_Loss_phi, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
